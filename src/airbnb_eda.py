# -*- coding: utf-8 -*-
"""AIRBNB EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iP4dxPZH16zB1WapEDpWno_xDbcxX2Tz

EDA AIRBNB

1. EXPLORACIÓN DE LOS DATOS
"""

import pandas as pd

URL= "https://raw.githubusercontent.com/4GeeksAcademy/data-preprocessing-project-tutorial/main/AB_NYC_2019.csv"

total_data = pd.read_csv(URL)
total_data.head()

print(total_data.shape)

total_data.info()

print(total_data.describe())

"""Tipos de datos por columnas: decimales (3), númericos (7) y objetos (6)

Hay un total de 48895 filas (en este caso, pisos) y 16 columnas, entre las que encontramos el objetivo o clase a predecir, price.
Las variables Last_Review y reviews_per_moth contienen 10.052 valores nulos.Los valores completados representan el 20% del total de los valores.

2. ELIMINAMOS FILAS DUPLICADAS.
"""

total_data.drop(["id"], axis = 1, inplace = True)
total_data.head()

"""Eliminamos la variable "id" porque puede estar mal asignada y contener valores duplicados"""

total_data.duplicated().sum()

"""No se encuentran filas con valores duplicados

3. ELIMINACIÓN DE LAS VARIABLES NO NECESARIAS PARA NUESTRO MODELO
                             
 1   name                            
 2   host_id                         
 3   host_name

 5   neighbourhood                   
 6   latitude                        
 7   longitude      
 12  last_review                     
 13  reviews_per_month      

 De las variables predictoras que eliminamos, las siguientes que enumeramos, son eliminadas porque ya contamos con otras variables en en nuestro Data Frame que agrupa esta información:
  
  5   neighbourhood    
  12  last_review                     
  13  reviews_per_month
"""

total_data.drop(["name", "host_id", "host_name","latitude","longitude","neighbourhood","last_review","reviews_per_month"], axis = 1, inplace = True)
total_data.head()

"""4. ANÁLISIS DE VARIABLES

VARIABLES CATEGÓRICAS
"""

import matplotlib.pyplot as plt
import seaborn as sns
fig, axis = plt.subplots(1,2,figsize = (8,5))

# Create a multiple histogram

sns.histplot(ax = axis[0], data = total_data, x = "neighbourhood_group").set(ylabel = None)
sns.histplot(ax = axis[1], data = total_data, x = "room_type").set(ylabel = None)



# Adjust the layout
plt.tight_layout()

# Show the plot
plt.show()

"""VARIABLES NUMÉRICAS"""

fig, axis = plt.subplots(4, 3, figsize = (15, 7), gridspec_kw={'height_ratios': [6,1,6,1]})


# Creating a multiple figure with histograms and box plots
sns.histplot(ax = axis[0, 0], data = total_data[total_data['price']<1000], x = "price").set(xlabel = None,ylabel = None)
sns.boxplot(ax = axis[1, 0], data = total_data, x = "price")
sns.histplot(ax = axis[0, 1], data = total_data[total_data['minimum_nights']<10], x = "minimum_nights").set(xlabel = None, ylabel = None)
sns.boxplot(ax = axis[1, 1], data = total_data, x = "minimum_nights")
sns.histplot(ax = axis[0, 2], data = total_data[total_data["number_of_reviews"]<50], x = "number_of_reviews").set(xlabel = None, ylabel = None)
sns.boxplot(ax = axis[1, 2], data = total_data, x = "number_of_reviews")
sns.histplot(ax = axis[2, 0], data = total_data[total_data['calculated_host_listings_count']<10], x = "calculated_host_listings_count").set(xlabel = None, ylabel = None)
sns.boxplot(ax = axis[3, 0], data = total_data, x = "calculated_host_listings_count")
sns.histplot(ax = axis[2, 1], data = total_data[total_data["availability_365"]<10], x = "availability_365").set(xlabel = None, ylabel = None)
sns.boxplot(ax = axis[3, 1], data = total_data, x = "availability_365")

# Adjust the layout
plt.tight_layout()

# Show the plot
plt.show()

"""Comparamos la relación entre el nuestra variable target "precio" y las variables predictoras"""

fig, axis = plt.subplots(4, 2, figsize = (10, 7))

# Create a multiple scatter diagram
sns.regplot(ax = axis[0, 0], data = total_data, x = "price", y = "minimum_nights")
sns.heatmap(total_data[["price", "minimum_nights"]].corr(), annot = True, fmt = ".2f", ax = axis[0,1], cbar = False)
sns.regplot(ax = axis[1, 0], data = total_data, x = "price", y = "number_of_reviews")
sns.heatmap(total_data[["price", "number_of_reviews"]].corr(), annot = True, fmt = ".2f", ax = axis[1, 1])
sns.regplot(ax = axis[2, 0], data = total_data, x = "price", y = "calculated_host_listings_count")
sns.heatmap(total_data[["price", "calculated_host_listings_count"]].corr(), annot = True, fmt = ".2f", ax = axis[2, 1])
sns.regplot(ax = axis[3, 0], data = total_data, x = "price", y = "availability_365")
sns.heatmap(total_data[["price", "availability_365"]].corr(), annot = True, fmt = ".2f", ax = axis[3, 1])





# Adjust the layout
plt.tight_layout()

# Show the plot
plt.show()

"""No se aprecias correlaciones significtivas entre las variables númericas y el precio

VARIABLES CATEGÓRICAS
"""

fig, axis = plt.subplots(1, 2, figsize = (15, 7))

sns.countplot(ax = axis[0], data = total_data, x = "neighbourhood_group", hue = "price").set(ylabel=None)
sns.countplot(ax = axis[1], data = total_data, x = "room_type", hue = "price").set(ylabel = None)



plt.tight_layout()


plt.show()

"""Interpretamos en un primer momento que el precio de los alquileres se ve influenciado por la ubicación de la oferta así como la tipología de de unidad habitacional ofertada.

EXPLORACIÓN DE LA NUESTRO TARGET CON VARIAS VARIABLES PREDICTORAS
"""

fig, ax = plt.subplots(1, 1, figsize = (10, 7))
sns.barplot(data = total_data, x = "neighbourhood_group", y = "price", hue = "room_type")


plt.tight_layout()

plt.show()

"""Las habitaciones privadas y compartir habitación son las tipológías que más variación muestran según su ubicación, en cambio. el alquiler de viviendas mantiene unos rango de preciós más uniformes a excepción del barrio de Manhattan. Está última anotación nos confirma que la ubicación de la oferta es la variable que más influye en el precio.

5. TRANSFORMACIÓN DE LAS VARIABLES CATÉGORICAS EN VALORES NORMALIZADOS (NUMÉRICOS)
"""

import json

factorize = pd.factorize(total_data["neighbourhood_group"])
parsing_dict = {}
indices = factorize[1]
set_factor = list(set(factorize[0]))
for index in range(len(factorize[1])):
  parsing_dict.update({indices[index]: int(set_factor[index])})

with open("transform_neighbourhood_group.json", "w") as f:
  json.dump(parsing_dict, f)
total_data["neighbourhood_group_n"] = factorize[0]


factorize = pd.factorize(total_data["room_type"])
parsing_dict = {}
indices = factorize[1]
set_factor = list(set(factorize[0]))
for index in range(len(factorize[1])):
  parsing_dict.update({indices[index]: int(set_factor[index])})

with open("transform_room_type.json", "w") as f:
  json.dump(parsing_dict, f)
total_data["room_type_n"] = factorize[0]

"""6. ANÁLISIS COMPLETO DE LA CORRELACIÓN DE TODAS LAS VARIABLES UNA VEZ NORMALIZADAS LAS VARIABLES CATEGORICAS"""

fig, axis = plt.subplots(figsize = (15, 7))
sns.heatmap(total_data[["neighbourhood_group_n", "room_type_n", "minimum_nights", "number_of_reviews", "calculated_host_listings_count", "availability_365", "price"]].corr(), annot = True, fmt = ".2f")

plt.tight_layout()

plt.show()

"""La correlación de todas las variables nos indica los siguiente:
- El tipo de habitación es la variable que más determina el precio de la oferta y no la ubicación
- La ubicación tiene una correlación significativa sobre la disponibilidad, los barrios pueden caracterizarse por ser mayoritariamente residentes o mayoritariamente oferta orientada al turismo.
  Ésto explica también la fuerte correlación entre la disponibilidad, las noches mínimas y el anfitrion, puesto que si no es residente de la vivienda que oferta la disponibilidad aumenta en consegcuencia así como su flexibilidad para ofertarla para períodos de menos duración.
- Nº de opiniones y opiniones por mes son dos variables que se pueden unir por su extracha vinculación.
- La correlación entre opiniones de los usuarios y oferta de mínimo de noches se relaciona con a mayor transito de usuarios mayor flujo de opiniones.

Confirmamos correlación con:

Tipo de habitación con precio
Anfitrión con diponibilidad
"""

fig, axis = plt.subplots(2,2,figsize = (10, 5))

sns.regplot(ax = axis[0,0], data = total_data, x = "price", y = "room_type_n")
sns.heatmap(total_data[["price","room_type_n"]].corr(),annot=True,fmt=".2f",ax=axis[1,0],cbar=False)
sns.regplot(ax = axis[0,1], data = total_data, x = "calculated_host_listings_count", y = "availability_365").set(ylabel = None, ylim = (0.9, 3.1))
sns.heatmap(total_data[["calculated_host_listings_count","availability_365"]].corr(),annot=True,fmt=".2f",ax=axis[1,1],cbar=False)
plt.tight_layout()

plt.show()

sns.pairplot(data = total_data)

"""FEATURE ENGINEERING // OUTLIERS"""

# Antes de actuar sobre los outliers creamos una copia con outliers y otra sin outliers
total_data_con_outliers=total_data.copy()
total_data_sin_outliers=total_data.copy()
total_data_con_outliers.to_csv("/content/sample_data/total_data_con_outliers.csv", index=False)
total_data_sin_outliers.to_csv("/content/sample_data/total_data_sin_outliers.csv", index=False)

total_stats =total_data.describe()
total_stats

fig, axis = plt.subplots(4, 2, figsize = (10, 10))

sns.boxplot(ax = axis[0, 0], data = total_data, y = "price") # grafitamos la target pero no actuamos sobre ella
sns.boxplot(ax = axis[1, 0], data = total_data, y = "minimum_nights")
sns.boxplot(ax = axis[2, 0], data = total_data, y = "number_of_reviews")
sns.boxplot(ax = axis[3, 0], data = total_data, y = "calculated_host_listings_count")
sns.boxplot(ax = axis[0, 1], data = total_data, y = "availability_365")
sns.boxplot(ax = axis[1, 1], data = total_data, y = "neighbourhood_group_n")
sns.boxplot(ax = axis[2, 1], data = total_data, y = "room_type_n")

plt.tight_layout()

plt.show()

"""Variables afectados por outliers:"price","minimum_nights","number_of_reviews","calculated_host_listings_count"y"neighbourhood_group_n"

Modificaremos los outliers de las variables:"minimum_nights" y "number_of_reviews"
"""

minimum_nights_stats = total_data["minimum_nights"].describe()
number_of_reviews_stats = total_data["number_of_reviews"].describe()

minimum_nights_iqr = minimum_nights_stats["75%"] - minimum_nights_stats["25%"]
upper_limit_mn = minimum_nights_stats["75%"] + 2 * minimum_nights_iqr
lower_limit_mn = minimum_nights_stats["25%"] - 2 * minimum_nights_iqr
if (lower_limit_mn<0): lower_limit_mn=0
total_data_sin_outliers["minimum_nights"]=total_data_sin_outliers["minimum_nights"].apply(lambda x:upper_limit_mn if (x > upper_limit_mn)else x)
print(f"minimum_nights: los límites superior e inferior para la búsqueda de outliers son {round(upper_limit_mn, 2)} y {round(lower_limit_mn, 2)}, con un rango intercuartílico de {round(minimum_nights_iqr, 2)}")
total_data_sin_outliers["minimum_nights"].describe()

number_of_reviews_iqr = number_of_reviews_stats["75%"] - number_of_reviews_stats["25%"]
upper_limit_nr = number_of_reviews_stats["75%"] + 2 * number_of_reviews_iqr
lower_limit_nr = number_of_reviews_stats["25%"] - 2 * number_of_reviews_iqr
if (lower_limit_nr<0): lower_limit_nr=0
total_data_sin_outliers["number_of_reviews"]=total_data_sin_outliers["number_of_reviews"].apply(lambda x:upper_limit_nr if (x > upper_limit_nr)else x)
print(f"number_of_reviews: los límites superior e inferior para la búsqueda de outliers son {round(upper_limit_nr, 2)} y {round(lower_limit_nr, 2)}, con un rango intercuartílico de {round(number_of_reviews_iqr, 2)}")
total_data_sin_outliers["number_of_reviews"].describe()

total_data_con_outliers.to_csv("/content/sample_data/total_data_con_outliers.csv", index=False)
total_data_sin_outliers.to_csv("/content/sample_data/total_data_sin_outliers.csv", index=False)

"""CREAR DICCIONARIO PARA LOS OUTLIERS"""

with open("transform_minimum_nights.json", "w") as f:
  json.dump({"upper_limit_mn":upper_limit_mn,"lower_limit_mn":lower_limit_mn}, f)

with open("transform_number_of_reviews.json", "w") as f:
  json.dump({"upper_limit_nr":upper_limit_nr,"lower_limit_nr":lower_limit_nr}, f)

"""ANÁLISIS DE VALORES FALTANTES / isnull()"""

total_data_sin_outliers.isnull().sum().sort_values(ascending=True)

"""No encontramos valores nulos

ESCALADO DE VALORES (feature scaling)
"""

from sklearn.model_selection import train_test_split

num_variables = ["minimum_nights","number_of_reviews","calculated_host_listings_count","availability_365","neighbourhood_group_n","room_type_n"]
X = total_data_sin_outliers.drop("price", axis = 1)[num_variables]
y = total_data_sin_outliers["price"]

# # Dividimos el conjunto de datos en muestras de train y test
X_con = total_data_con_outliers.drop("price", axis = 1)[num_variables]
y_con = total_data_con_outliers["price"]
X_sin = total_data_sin_outliers.drop("price", axis = 1)[num_variables]
y_sin = total_data_sin_outliers["price"]

X_con_train, X_con_test, y_train, y_test = train_test_split(X_con, y_con, test_size = 0.2, random_state = 42)
X_sin_train, X_sin_test,_,_ = train_test_split(X_sin, y_sin, test_size = 0.2, random_state = 42)

X_con_train.head()

X_sin_train.head()

X_con_train.to_csv("/content/sample_data/X_con_train.csv", index=False)
X_con_test.to_csv("/content/sample_data/X_con_test.csv", index=False)
X_sin_train.to_csv("/content/sample_data/X_sin_train.csv", index=False)
X_sin_test.to_csv("/content/sample_data/X_sin_test.csv", index=False)

"""NORMALIZACIÓN"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_con_train)
scaler.fit(X_sin_train)

X_con_train_norm = scaler.transform(X_con_train)
X_con_train_norm = pd.DataFrame(X_con_train_norm, index = X_con_train.index, columns = num_variables)

X_sin_train_norm = scaler.transform(X_sin_train)
X_sin_train_norm = pd.DataFrame(X_sin_train_norm, index = X_sin_train.index, columns = num_variables)


X_con_test_norm = scaler.transform(X_con_test)
X_con_test_norm = pd.DataFrame(X_con_test_norm, index = X_con_test.index, columns = num_variables)


X_sin_test_norm = scaler.transform(X_sin_test)
X_sin_test_norm = pd.DataFrame(X_sin_test_norm, index = X_sin_test.index, columns = num_variables)

X_con_train_norm.to_csv("/content/sample_data/X_con_train_sin_norm.csv", index=False)
X_con_test_norm.to_csv("/content/sample_data/X_con_test_sin_norm.csv", index=False)
X_sin_train_norm.to_csv("/content/sample_data/X_sin_train_sin_norm.csv", index=False)
X_sin_test_norm.to_csv("/content/sample_data/X_sin_test_sin_norm.csv", index=False)

"""ESCALADO MÍNIMO-MÁXIMO"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaler.fit(X_con_train)


X_con_train_scal = scaler.transform(X_con_train)
X_con_train_scal = pd.DataFrame(X_con_train_scal, index = X_con_train.index, columns = num_variables)

X_con_test_scal = scaler.transform(X_con_test)
X_con_test_scal = pd.DataFrame(X_con_test_scal, index = X_con_test.index, columns = num_variables)

X_con_train_scal.head()

scaler.fit(X_sin_train)

X_sin_train_scal = scaler.transform(X_sin_train)
X_sin_train_scal = pd.DataFrame(X_sin_train_scal, index = X_sin_train.index, columns = num_variables)

X_sin_test_scal = scaler.transform(X_sin_test)
X_sin_test_scal = pd.DataFrame(X_sin_test_scal, index = X_sin_test.index, columns = num_variables)

X_sin_train_scal.head()

X_con_train_scal.to_csv("/content/sample_data/Escalado/X_con_train_scal.csv", index=False)
X_con_test_scal.to_csv("/content/sample_data/Escalado/X_con_test_scal.csv", index=False)
X_sin_train_scal.to_csv("/content/sample_data/Escalado/X_sin_train_scal.csv", index=False)
X_sin_test_scal.to_csv("/content/sample_data/Escalado/X_sin_test_scal.csv", index=False)